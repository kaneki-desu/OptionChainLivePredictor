{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad875fdd",
   "metadata": {},
   "source": [
    "<h2 style=\"Color:Yellow\">Percentage change</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9787409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Load your data\n",
    "data= np.load(\"Train_Data/option_train_labeled.npz\", allow_pickle=True)\n",
    "X_all = data['X']\n",
    "Y_all = data['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a78dd",
   "metadata": {},
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dc800aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def engineer_features_torch(X_all_np, device='cuda'):\n",
    "    X = torch.tensor(X_all_np, dtype=torch.float32, device=device)  # (N, 15, 10)\n",
    "    eps = 1e-6\n",
    "\n",
    "    # Extract columns\n",
    "    N_open = X[:, :, 0]\n",
    "    N_close = X[:, :, 1]\n",
    "    opt_type = X[:, :, 4]\n",
    "    open_ = X[:, :, 5]\n",
    "    close = X[:, :, 6]\n",
    "    oi = X[:, :, 7]\n",
    "    strike = X[:, :, 8]\n",
    "    tte = X[:, :, 9]\n",
    "\n",
    "    return_pct = (close - open_) / (open_ + eps)\n",
    "    candle_dir = torch.sign(close - open_)\n",
    "    candle_body_pct = torch.abs(close - open_) / (open_ + eps)\n",
    "\n",
    "    nifty_return_pct = (N_close - N_open) / (N_open + eps)\n",
    "    nifty_candle_dir = torch.sign(nifty_return_pct)\n",
    "    nifty_vs_option_corr = torch.sign(nifty_return_pct * return_pct)\n",
    "\n",
    "    # OI change\n",
    "    oi_prev = torch.cat([oi[:, :1], oi[:, :-1]], dim=1)\n",
    "    oi_change_pct = (oi - oi_prev) / (oi_prev + eps)\n",
    "    oi_price_corr = torch.sign(oi_change_pct * return_pct)\n",
    "\n",
    "    strike_distance = torch.abs(N_close - strike) / (N_close + eps)\n",
    "\n",
    "    # Rolling features (window=5)\n",
    "    def rolling(x, window=5):\n",
    "        # shape: (N, 15-window+1)\n",
    "        unfold = x.unfold(dimension=1, size=window, step=1)  # (N, T-window+1, window)\n",
    "        mean = unfold.mean(dim=-1)\n",
    "        std = unfold.std(dim=-1)\n",
    "        # pad to match original sequence length\n",
    "        pad_left = window - 1\n",
    "        mean = torch.cat([mean[:, :1].repeat(1, pad_left), mean], dim=1)\n",
    "        std = torch.cat([std[:, :1].repeat(1, pad_left), std], dim=1)\n",
    "        return mean, std\n",
    "\n",
    "    rolling_mean_ret, rolling_std_ret = rolling(return_pct)\n",
    "    rolling_mean_oi, _ = rolling(oi_change_pct)\n",
    "\n",
    "    # Bullish ratio\n",
    "    bullish_ratio = (candle_dir > 0).float().sum(dim=1, keepdim=True) / 15.0\n",
    "    bullish_ratio = bullish_ratio.repeat(1, 15)\n",
    "\n",
    "    # Stack all features: (N, 15, F)\n",
    "    X_feat = torch.stack([\n",
    "        return_pct,\n",
    "        candle_dir,\n",
    "        candle_body_pct,\n",
    "        oi_change_pct,\n",
    "        oi_price_corr,\n",
    "        nifty_return_pct,\n",
    "        nifty_candle_dir,\n",
    "        nifty_vs_option_corr,\n",
    "        tte,\n",
    "        strike_distance,\n",
    "        opt_type,\n",
    "        rolling_mean_ret,\n",
    "        rolling_std_ret,\n",
    "        rolling_mean_oi,\n",
    "        bullish_ratio\n",
    "    ], dim=-1)\n",
    "\n",
    "    return X_feat  # (N, 15, 15)\n",
    "\n",
    "def create_labels_torch(X_all_np, Y_all_np, device='cuda'):\n",
    "    X = torch.tensor(X_all_np, dtype=torch.float32, device=device)\n",
    "    Y = torch.tensor(Y_all_np[:, :3], dtype=torch.float32, device=device)  # use only y1, y2, y3\n",
    "\n",
    "    last_close = X[:, -1, 6]  # last close from input\n",
    "\n",
    "    y1, y2, y3 = Y[:, 0], Y[:, 1], Y[:, 2]\n",
    "\n",
    "    # Strictly increasing\n",
    "    inc_1 = y1 > last_close\n",
    "    inc_2 = y2 > y1\n",
    "    inc_3 = y3 > y2\n",
    "\n",
    "    label = (inc_1 & inc_2 & inc_3).long()  # 1 = BUY, 0 = NO BUY\n",
    "    return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef5bd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Feature tensor shape: torch.Size([2383014, 15, 15])\n",
      "⏱️ Time taken (GPU): 10.68 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Load your data (already in RAM as NumPy)\n",
    "X_all = X_all.astype(np.float64)\n",
    "\n",
    "start = time.time()\n",
    "X_feat_torch = engineer_features_torch(X_all, device='cuda')\n",
    "torch.cuda.synchronize()\n",
    "print(\"✅ Done. Feature tensor shape:\", X_feat_torch.shape)\n",
    "print(\"⏱️ Time taken (GPU):\", round(time.time() - start, 2), \"sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d29f0388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Label tensor shape: torch.Size([2383014])\n",
      "✅ BUY samples: 123602\n"
     ]
    }
   ],
   "source": [
    "labels_torch = create_labels_torch(X_all, Y_all, device='cuda')\n",
    "print(\"✅ Label tensor shape:\", labels_torch.shape)\n",
    "print(\"✅ BUY samples:\", torch.sum(labels_torch).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61e7c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to options_buy_model_data.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "    'X': X_feat_torch,       # shape: (2383014, 15, 15)\n",
    "    'Y': torch.tensor(Y_all, dtype=torch.float32, device='cuda'),  # shape: (2383014, 5)\n",
    "    'labels': labels_torch   # shape: (2383014,)\n",
    "}, 'Train_Data/options_buy_model_data.pt')\n",
    "\n",
    "print(\"✅ Saved to options_buy_model_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "| Index | Feature Name               | Description                                     |\n",
    "| ----- | -------------------------- | ----------------------------------------------- |\n",
    "| 0     | `return_pct`               | (close - open) / open                           |\n",
    "| 1     | `candle_dir`               | Direction of candle (+1, 0, -1)                 |\n",
    "| 2     | `candle_body_pct`          | abs(close - open) / open                        |\n",
    "| 3     | `oi_change_pct`            | % change in open interest from previous bar     |\n",
    "| 4     | `oi_price_corr`            | Sign of oi\\_change × return\\_pct                |\n",
    "| 5     | `nifty_return_pct`         | NIFTY return % over that minute                 |\n",
    "| 6     | `nifty_candle_dir`         | NIFTY direction sign                            |\n",
    "| 7     | `nifty_vs_option_corr`     | Sign of (nifty\\_return × option\\_return)        |\n",
    "| 8     | `time_to_expiry`           | Time (in days) to expiry                        |\n",
    "| 9     | `strike_distance`          | abs(Nifty\\_close - strike) / Nifty\\_close       |\n",
    "| 10    | `option_type`              | 1 for CE, -1 for PE                             |\n",
    "| 11    | `rolling_mean_return_5`    | Rolling mean of return\\_pct (window=5)          |\n",
    "| 12    | `rolling_std_return_5`     | Rolling std deviation of return\\_pct (window=5) |\n",
    "| 13    | `rolling_mean_oi_change_5` | Rolling mean of oi\\_change\\_pct (window=5)      |\n",
    "| 14    | `bullish_candle_ratio`     | Ratio of positive candles in the 15-step window |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ef8cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6f01f",
   "metadata": {},
   "source": [
    "<h3>5min labelled</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf75fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. X shape: (188860, 15, 10) Y shape: (188860, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "root_dir = \"Data3\"\n",
    "sequence_length = 15\n",
    "lookahead = 5\n",
    "\n",
    "features = [\n",
    "    'Nifty_open', 'Nifty_close', 'Nifty_high', 'Nifty_low','type',\n",
    "    'open', 'close', 'open_interest',\n",
    "    'strike', 'time_to_expiry'\n",
    "]\n",
    "\n",
    "X_all = []\n",
    "Y_all = []\n",
    "\n",
    "# Get all matching CSV files in subfolders\n",
    "# all_csvs = glob(os.path.join(root_dir, \"exp_date_2025-06-26*\", \"*_NIFTY_nearby_5strikeprices.csv\"))\n",
    "all_csvs = glob(os.path.join(root_dir, \"exp_date_*\", \"*_NIFTY_nearby_5strikeprices.csv\"))\n",
    "for file_path in all_csvs:\n",
    "    try:\n",
    "        df= pd.read_csv(file_path)\n",
    "\n",
    "        # Keep NIFTY OHLC columns and datetime separately\n",
    "        id_vars = ['datetime', 'open', 'high', 'low', 'close']\n",
    "\n",
    "        # Melt all other option columns\n",
    "        value_vars = [col for col in df.columns if col not in id_vars]\n",
    "        long_df = df.melt(\n",
    "            id_vars=id_vars,\n",
    "            value_vars=value_vars,\n",
    "            var_name='option_meta',  # will hold the original column names\n",
    "            value_name='value'       # will hold the actual numbers\n",
    "        )\n",
    "        # Extract expiry, strike, type, field from option_meta\n",
    "        option_parts = long_df['option_meta'].str.extract(\n",
    "            r'NIFTY(?P<expiry>\\d{4}-\\d{2}-\\d{2})\\|(?P<strike>\\d+)(?P<type>CE|PE)_(?P<field>\\w+)'\n",
    "        )\n",
    "        # Combine with main DataFrame\n",
    "        df_clean = pd.concat([long_df, option_parts],axis=1)\n",
    "        df_clean.rename(columns={\n",
    "            'open': 'Nifty_open',\n",
    "            'close': 'Nifty_close',\n",
    "            'high': 'Nifty_high',\n",
    "            'low': 'Nifty_low'\n",
    "        }, inplace=True)\n",
    "        # Pivot the 'field' values into columns (open, open_interest, etc.)\n",
    "        df_pivoted = df_clean.pivot_table(\n",
    "            index=['datetime', 'expiry', 'strike', 'type','Nifty_open','Nifty_close','Nifty_high','Nifty_low'],\n",
    "            columns='field',\n",
    "            values='value',\n",
    "            aggfunc='first'  # in case of duplicates\n",
    "        ).reset_index()\n",
    "\n",
    "        df_pivoted['datetime'] = pd.to_datetime(df_pivoted['datetime'])\n",
    "        df_pivoted['expiry'] = pd.to_datetime(df_pivoted['expiry'])\n",
    "        df_pivoted['strike'] = df_pivoted['strike'].astype(int)\n",
    "        # Time to expiry in fractional days (can include hours/minutes)\n",
    "        df_pivoted['time_to_expiry'] = (df_pivoted['expiry']- pd.Timedelta(\"-1 days +08:30:01\") - df_pivoted['datetime']).dt.total_seconds() / (60 * 60 * 24)\n",
    "        df_pivoted['type'] = df_pivoted['type'].map({'CE': 1, 'PE': -1})\n",
    "\n",
    "        sequence_length = 15\n",
    "        lookahead = 5\n",
    "        features = [\n",
    "            'Nifty_open', 'Nifty_close', 'Nifty_high', 'Nifty_low','type',\n",
    "            'open', 'close', 'open_interest',\n",
    "            'strike',  'time_to_expiry'\n",
    "        ]\n",
    "\n",
    "        # Convert datetime just once\n",
    "        df_pivoted['datetime'] = pd.to_datetime(df_pivoted['datetime'])\n",
    "\n",
    "        # Group by unique combinations\n",
    "        unique_combinations = df_pivoted[['strike', 'type', 'expiry']].drop_duplicates()\n",
    "\n",
    "        for _, row in unique_combinations.iterrows():\n",
    "            strike = row['strike']\n",
    "            option_type = row['type']\n",
    "            expiry = row['expiry']\n",
    "\n",
    "            df_filtered = df_pivoted[\n",
    "                (df_pivoted['strike'] == strike) &\n",
    "                (df_pivoted['type'] == option_type) &\n",
    "                (df_pivoted['expiry'] == expiry)\n",
    "            ].sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "            if len(df_filtered) < sequence_length + lookahead:\n",
    "                continue  # Skip if not enough data\n",
    "            \n",
    "            data = df_filtered[features].values\n",
    "            \n",
    "            for i in range(len(data) - sequence_length - lookahead):\n",
    "                x_seq = data[i:i + sequence_length]\n",
    "                y_seq = data[i + sequence_length : i + sequence_length + lookahead]\n",
    "                close_col = y_seq[:, 6]  # Index for 'close'\n",
    "\n",
    "                X_all.append(x_seq)\n",
    "                Y_all.append(close_col)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file_path}: {e}\")\n",
    "        # Convert to arrays\n",
    "X_all = np.array(X_all)\n",
    "Y_all = np.array(Y_all)\n",
    "print(\"✅ Done. X shape:\", X_all.shape, \"Y shape:\", Y_all.shape)\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d836ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved at: Train_Data\\option_train_data_06_06_2025.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create DataFrame\n",
    "combined_df = pd.DataFrame({\n",
    "    'X_all': [x.tolist() for x in X_all],\n",
    "    'Y_all': [y.tolist() for y in Y_all]\n",
    "})\n",
    "\n",
    "# Step 5: Save to CSV\n",
    "output_dir = 'Train_Data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'option_train_data_06_06_2025.csv')\n",
    "\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "print(f\"✅ CSV saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3171a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved as compressed .npz for efficient loading.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "output_dir = 'Train_Data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "np.savez_compressed(\n",
    "    os.path.join(output_dir, 'option_train_data_06_06_2025.npz'),\n",
    "    X_all=np.array(X_all),\n",
    "    Y_all=np.array(Y_all)\n",
    ")\n",
    "\n",
    "print(\"✅ Saved as compressed .npz for efficient loading.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ff8d2",
   "metadata": {},
   "source": [
    "<h3>Normalisation of data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc905dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Standardization done and saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# === Load Data ===\n",
    "X_all, Y_all ,labels= np.load(\"Train_Data/option_train_labeled_3m.npz\", allow_pickle=True).values()\n",
    "feature_columns = [\n",
    "    'Nifty_open',\n",
    "    'Nifty_close', 'Nifty_high', 'Nifty_low',\n",
    "    'type',\n",
    "    'open', 'close', 'open_interest',\n",
    "    'strike', 'time_to_expiry'\n",
    "]\n",
    "\n",
    "cols_to_normalize = [\n",
    "    'Nifty_open', 'Nifty_close', 'Nifty_high', 'Nifty_low',\n",
    "    'open', 'close', 'open_interest',\n",
    "    'strike', 'time_to_expiry'\n",
    "]\n",
    "\n",
    "cols_idx_to_normalize = [feature_columns.index(col) for col in cols_to_normalize]\n",
    "\n",
    "n_samples, seq_len, n_features = X_all.shape\n",
    "X_reshaped = X_all.reshape(-1, n_features)\n",
    "\n",
    "scaler_X = {}\n",
    "\n",
    "# Standardize only the selected features\n",
    "for idx in cols_idx_to_normalize:\n",
    "    feature = feature_columns[idx]\n",
    "    scaler = StandardScaler()\n",
    "    X_reshaped[:, idx] = scaler.fit_transform(X_reshaped[:, idx].reshape(-1, 1)).flatten()\n",
    "    scaler_X[feature] = scaler\n",
    "\n",
    "# Reshape back to 3D\n",
    "X_all_scaled = X_reshaped.reshape(n_samples, seq_len, n_features)\n",
    "\n",
    "# === Standardize Y_all ===\n",
    "scaler_Y = StandardScaler()\n",
    "Y_all_scaled = scaler_Y.fit_transform(Y_all)\n",
    "\n",
    "# Save the scaled data and scalers\n",
    "np.savez_compressed(\"Train_Data/option_Xscaled_3m.npz\", X_all=X_all_scaled, Y_all=Y_all_scaled, labels=labels)\n",
    "joblib.dump(scaler_X, \"Train_Data/scaler_X.pkl\")\n",
    "joblib.dump(scaler_Y, \"Train_Data/scaler_Y.pkl\")\n",
    "\n",
    "print(\"✅ Standardization done and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f886ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"Data3/exp_date_2025-03-27/2025-03-06_NIFTY_nearby_5strikeprices.csv\")\n",
    "# Keep NIFTY OHLC columns and datetime separately\n",
    "id_vars = ['datetime', 'open', 'high', 'low', 'close']\n",
    "\n",
    "# Melt all other option columns\n",
    "value_vars = [col for col in df.columns if col not in id_vars]\n",
    "long_df = df.melt(\n",
    "    id_vars=id_vars,\n",
    "    value_vars=value_vars,\n",
    "    var_name='option_meta',  # will hold the original column names\n",
    "    value_name='value'       # will hold the actual numbers\n",
    ")\n",
    "# Extract expiry, strike, type, field from option_meta\n",
    "option_parts = long_df['option_meta'].str.extract(\n",
    "    r'NIFTY(?P<expiry>\\d{4}-\\d{2}-\\d{2})\\|(?P<strike>\\d+)(?P<type>CE|PE)_(?P<field>\\w+)'\n",
    ")\n",
    "# Combine with main DataFrame\n",
    "df_clean = pd.concat([long_df, option_parts],axis=1)\n",
    "df_clean.rename(columns={\n",
    "    'open': 'Nifty_open',\n",
    "    'close': 'Nifty_close',\n",
    "    'high': 'Nifty_high',\n",
    "    'low': 'Nifty_low'\n",
    "}, inplace=True)\n",
    "# Pivot the 'field' values into columns (open, open_interest, etc.)\n",
    "df_pivoted = df_clean.pivot_table(\n",
    "    index=['datetime', 'expiry', 'strike', 'type','Nifty_open','Nifty_close','Nifty_high','Nifty_low'],\n",
    "    columns='field',\n",
    "    values='value',\n",
    "    aggfunc='first'  # in case of duplicates\n",
    ").reset_index()\n",
    "\n",
    "df_pivoted['datetime'] = pd.to_datetime(df_pivoted['datetime'])\n",
    "df_pivoted['expiry'] = pd.to_datetime(df_pivoted['expiry'])\n",
    "df_pivoted['strike'] = df_pivoted['strike'].astype(int)\n",
    "# Time to expiry in fractional days (can include hours/minutes)\n",
    "df_pivoted['time_to_expiry'] = (df_pivoted['expiry']- pd.Timedelta(\"-1 days +08:30:01\") - df_pivoted['datetime']).dt.total_seconds() / (60 * 60 * 24)\n",
    "df_pivoted['type'] = df_pivoted['type'].map({'CE': 1, 'PE': -1})\n",
    "df_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb426782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_all = []\n",
    "Y_all = []\n",
    "\n",
    "sequence_length = 15\n",
    "lookahead = 5\n",
    "features = [\n",
    "    'Nifty_open', 'Nifty_close', 'Nifty_high', 'Nifty_low','type',\n",
    "    'open', 'close', 'open_interest',\n",
    "    'strike',  'time_to_expiry'\n",
    "]\n",
    "\n",
    "# Convert datetime just once\n",
    "df_pivoted['datetime'] = pd.to_datetime(df_pivoted['datetime'])\n",
    "\n",
    "# Group by unique combinations\n",
    "unique_combinations = df_pivoted[['strike', 'type', 'expiry']].drop_duplicates()\n",
    "\n",
    "for _, row in unique_combinations.iterrows():\n",
    "    strike = row['strike']\n",
    "    option_type = row['type']\n",
    "    expiry = row['expiry']\n",
    "    \n",
    "    df_filtered = df_pivoted[\n",
    "        (df_pivoted['strike'] == strike) &\n",
    "        (df_pivoted['type'] == option_type) &\n",
    "        (df_pivoted['expiry'] == expiry)\n",
    "    ].sort_values('datetime').reset_index(drop=True)\n",
    "    \n",
    "    if len(df_filtered) < sequence_length + lookahead:\n",
    "        continue  # Skip if not enough data\n",
    "\n",
    "    data = df_filtered[features].values\n",
    "\n",
    "    for i in range(len(data) - sequence_length - lookahead):\n",
    "        x_seq = data[i:i + sequence_length]\n",
    "        y_seq = data[i + sequence_length : i + sequence_length + lookahead]\n",
    "        close_col = y_seq[:, 6]  # Index for 'close'\n",
    "        \n",
    "        X_all.append(x_seq)\n",
    "        Y_all.append(close_col)\n",
    "\n",
    "# Convert to arrays\n",
    "X_all = np.array(X_all)\n",
    "Y_all = np.array(Y_all)\n",
    "\n",
    "print(\"✅ Done. X shape:\", X_all.shape, \"Y shape:\", Y_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5699f75c",
   "metadata": {},
   "source": [
    "<h3 style=\"color:pink\">Strong buy , buy, don't buy training data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4edf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all shape: (2383014, 15, 10)\n",
      "Y_all shape: (2383014, 5)\n",
      "First X sample: [[2.24763500e+04 2.24519500e+04 2.24913000e+04 2.24174500e+04\n",
      "  1.00000000e+00 6.08450000e+02 6.09850000e+02 3.94500000e+04\n",
      "  2.19500000e+04 2.12604167e+01]\n",
      " [2.24523000e+04 2.24520000e+04 2.24658500e+04 2.24496500e+04\n",
      "  1.00000000e+00 6.70900000e+02 6.72850000e+02 3.14250000e+04\n",
      "  2.19500000e+04 2.12597222e+01]\n",
      " [2.24539000e+04 2.24474500e+04 2.24568500e+04 2.24432500e+04\n",
      "  1.00000000e+00 6.73950000e+02 6.78800000e+02 3.14250000e+04\n",
      "  2.19500000e+04 2.12590278e+01]\n",
      " [2.24455000e+04 2.24472500e+04 2.24494000e+04 2.24409500e+04\n",
      "  1.00000000e+00 6.76000000e+02 6.70200000e+02 3.14250000e+04\n",
      "  2.19500000e+04 2.12583333e+01]\n",
      " [2.24455500e+04 2.24327500e+04 2.24519000e+04 2.24318500e+04\n",
      "  1.00000000e+00 6.71100000e+02 6.69700000e+02 2.77500000e+04\n",
      "  2.19500000e+04 2.12576389e+01]\n",
      " [2.24331000e+04 2.24173500e+04 2.24464500e+04 2.24145000e+04\n",
      "  1.00000000e+00 6.68200000e+02 6.69750000e+02 2.77500000e+04\n",
      "  2.19500000e+04 2.12569444e+01]\n",
      " [2.24172000e+04 2.24078000e+04 2.24250500e+04 2.24044500e+04\n",
      "  1.00000000e+00 6.64150000e+02 6.51500000e+02 2.77500000e+04\n",
      "  2.19500000e+04 2.12562500e+01]\n",
      " [2.24076500e+04 2.23877500e+04 2.24076500e+04 2.23821500e+04\n",
      "  1.00000000e+00 6.52650000e+02 6.52650000e+02 2.77500000e+04\n",
      "  2.19500000e+04 2.12555556e+01]\n",
      " [2.23867000e+04 2.23801000e+04 2.23867000e+04 2.23715000e+04\n",
      "  1.00000000e+00 6.33550000e+02 6.33900000e+02 2.70750000e+04\n",
      "  2.19500000e+04 2.12548611e+01]\n",
      " [2.23808500e+04 2.23664500e+04 2.23848500e+04 2.23577000e+04\n",
      "  1.00000000e+00 6.33900000e+02 6.33900000e+02 2.70750000e+04\n",
      "  2.19500000e+04 2.12541667e+01]\n",
      " [2.23672000e+04 2.23704500e+04 2.23814000e+04 2.23604000e+04\n",
      "  1.00000000e+00 6.28350000e+02 6.20550000e+02 2.67750000e+04\n",
      "  2.19500000e+04 2.12534722e+01]\n",
      " [2.23674500e+04 2.23628000e+04 2.23778000e+04 2.23627500e+04\n",
      "  1.00000000e+00 6.20550000e+02 6.20550000e+02 2.67750000e+04\n",
      "  2.19500000e+04 2.12527778e+01]\n",
      " [2.23619000e+04 2.23559500e+04 2.23730500e+04 2.23543000e+04\n",
      "  1.00000000e+00 6.20550000e+02 6.20550000e+02 2.67750000e+04\n",
      "  2.19500000e+04 2.12520833e+01]\n",
      " [2.23552500e+04 2.23609500e+04 2.23676000e+04 2.23492000e+04\n",
      "  1.00000000e+00 6.20550000e+02 6.20550000e+02 2.67750000e+04\n",
      "  2.19500000e+04 2.12513889e+01]\n",
      " [2.23577500e+04 2.23622500e+04 2.23660500e+04 2.23568500e+04\n",
      "  1.00000000e+00 6.20550000e+02 6.20550000e+02 2.67750000e+04\n",
      "  2.19500000e+04 2.12506944e+01]]\n",
      "First Y sample: [620.55 622.9  622.9  622.9  598.8 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "X_all, Y_all = np.load(\"Train_Data/option_train_data_06_06_2025.npz\", allow_pickle=True).values()\n",
    "print(\"X_all shape:\", X_all.shape)\n",
    "print(\"Y_all shape:\", Y_all.shape)\n",
    "print(\"First X sample:\", X_all[0])\n",
    "print(\"First Y sample:\", Y_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with STRONG BUY: [ 371  464  860  907 1211 1378 1783 1790 1921 2174]\n",
      "\n",
      "Corresponding Y_all values:\n",
      "Index 371 - Y_all: [120.   122.35 129.05 135.5  137.25]\n",
      "Index 464 - Y_all: [ 92.95  93.5   93.75  94.6  103.  ]\n",
      "Index 860 - Y_all: [514.45 612.5  619.45 626.   692.6 ]\n",
      "Index 907 - Y_all: [638.   644.5  649.3  654.4  711.05]\n",
      "Index 1211 - Y_all: [ 93.95 101.75 102.3  135.95 149.4 ]\n",
      "Index 1378 - Y_all: [ 93.05  93.3   93.65 102.2  107.7 ]\n",
      "Index 1783 - Y_all: [120.6  129.75 133.7  147.05 147.5 ]\n",
      "Index 1790 - Y_all: [104.85 124.55 147.4  156.1  161.25]\n",
      "Index 1921 - Y_all: [104.   113.55 117.2  145.65 165.6 ]\n",
      "Index 2174 - Y_all: [484.25 487.75 493.2  507.35 508.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "X_all, Y_all ,labels= np.load(\"Train_Data/option_train_labeled.npz\", allow_pickle=True).values()\n",
    "# Find indices where label is \"STRONG BUY\"\n",
    "strong_buy_indices = np.where(labels == \"STRONG BUY\")[0]\n",
    "\n",
    "# Print first such index and the corresponding Y_all\n",
    "print(\"Indices with STRONG BUY:\", strong_buy_indices[:10])  # first 10 indices\n",
    "print(\"\\nCorresponding Y_all values:\")\n",
    "for idx in strong_buy_indices[:10]:  # show first 5 examples\n",
    "    print(f\"Index {idx} - Y_all: {Y_all[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3541845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with STRONG BUY: [ 371  464  860  907 1211 1378 1783 1790 1921 2174]\n",
      "\n",
      "Corresponding Y_all values:\n",
      "Index 371 - Y_all: [120.   122.35 129.05 135.5  137.25]\n",
      "Index 464 - Y_all: [ 92.95  93.5   93.75  94.6  103.  ]\n",
      "Index 860 - Y_all: [514.45 612.5  619.45 626.   692.6 ]\n",
      "Index 907 - Y_all: [638.   644.5  649.3  654.4  711.05]\n",
      "Index 1211 - Y_all: [ 93.95 101.75 102.3  135.95 149.4 ]\n",
      "Index 1378 - Y_all: [ 93.05  93.3   93.65 102.2  107.7 ]\n",
      "Index 1783 - Y_all: [120.6  129.75 133.7  147.05 147.5 ]\n",
      "Index 1790 - Y_all: [104.85 124.55 147.4  156.1  161.25]\n",
      "Index 1921 - Y_all: [104.   113.55 117.2  145.65 165.6 ]\n",
      "Index 2174 - Y_all: [484.25 487.75 493.2  507.35 508.  ]\n"
     ]
    }
   ],
   "source": [
    "# Find indices where label is \"STRONG BUY\"\n",
    "strong_buy_indices = np.where(labels == \"STRONG BUY\")[0]\n",
    "\n",
    "# Print first such index and the corresponding Y_all\n",
    "print(\"Indices with STRONG BUY:\", strong_buy_indices[:10])  # first 10 indices\n",
    "print(\"\\nCorresponding Y_all values:\")\n",
    "for idx in strong_buy_indices[:10]:  # show first 5 examples\n",
    "    print(f\"Index {idx} - Y_all: {Y_all[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c66a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "X_all, Y_all = np.load(\"Train_Data/option_train_data_06_06_2025.npz\", allow_pickle=True).values()\n",
    "\n",
    "# Configuration\n",
    "close_price_index = 6  \n",
    "\n",
    "labels = []\n",
    "for x_seq, y_seq in zip(X_all, Y_all):\n",
    "    current_close = x_seq[-1][close_price_index]\n",
    "    future_close_5 = y_seq[4]\n",
    "\n",
    "    # Rule 1: Check for STRONG BUY\n",
    "    if (future_close_5 > current_close + 10) and all(y_seq[i+1] > y_seq[i] for i in range(4)):\n",
    "        labels.append(\"STRONG BUY\")\n",
    "    # Rule 2: Check for BUY\n",
    "    elif (future_close_5 > current_close + 10):\n",
    "        labels.append(\"BUY\")\n",
    "    # Rule 3: DON'T BUY\n",
    "    else:\n",
    "        labels.append(\"NO\")\n",
    "\n",
    "# Convert labels to a NumPy array (optional: encode as integers if needed)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Example: Save this dataset\n",
    "np.savez(\"Train_Data/option_train_labeled_06_06_2025.npz\", X=X_all, Y=Y_all, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab54ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "X_all, Y_all = np.load(\"Train_Data/option_train_data.npz\", allow_pickle=True).values()\n",
    "\n",
    "# Configuration\n",
    "close_price_index = 6  \n",
    "\n",
    "labels = []\n",
    "for x_seq, y_seq in zip(X_all, Y_all):\n",
    "    current_close = x_seq[-1][close_price_index]\n",
    "    future_close_5 = y_seq[4]\n",
    "\n",
    "    # Rule 1: Check for STRONG BUY\n",
    "    if (future_close_5 > current_close + 10) and all(y_seq[i+1] > y_seq[i] for i in range(4)):\n",
    "        labels.append(\"STRONG BUY\")\n",
    "    # Rule 2: Check for BUY\n",
    "    elif (future_close_5 > current_close + 10):\n",
    "        labels.append(\"BUY\")\n",
    "    # Rule 3: DON'T BUY\n",
    "    else:\n",
    "        labels.append(\"NO\")\n",
    "\n",
    "# Convert labels to a NumPy array (optional: encode as integers if needed)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Example: Save this dataset\n",
    "np.savez(\"Train_Data/option_train_labeled_3m.npz\", X=X_all, Y=Y_all, labels=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35123663",
   "metadata": {},
   "source": [
    "<h3>3 Min data BUY or NO</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64209f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "X_all, Y_all ,_= np.load(\"Train_Data/option_train_labeled_06_06_2025.npz\", allow_pickle=True).values()\n",
    "\n",
    "# Configuration\n",
    "close_price_index = 6  # Index for the close price in your feature vector\n",
    "\n",
    "labels = []\n",
    "for x_seq, y_seq in zip(X_all, Y_all):\n",
    "    current_close = x_seq[-1][close_price_index]\n",
    "    future_close_3 = y_seq[2]  # 3-minute future close price\n",
    "\n",
    "    # New BUY condition\n",
    "    if (future_close_3 > current_close + 5) and (y_seq[0] < y_seq[1] < y_seq[2]):\n",
    "        labels.append(\"BUY\")\n",
    "    else:\n",
    "        labels.append(\"NO\")\n",
    "\n",
    "# Convert labels to a NumPy array\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Save the updated dataset\n",
    "np.savez(\"Train_Data/option_train__labeled_3m_06_06_2025.npz\", X=X_all, Y=Y_all, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5eb1402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with BUY: (15354,)\n",
      "Indices with STRONG BUY: [293 361 389 431 494 512 526 555 573 586]\n",
      "\n",
      "Corresponding Y_all values:\n",
      "Index 293 - Y_all: [653.45 680.   715.95 680.   680.  ]\n",
      "Index 361 - Y_all: [167.15 170.1  176.   170.45 169.15]\n",
      "Index 389 - Y_all: [163.95 164.8  175.6  164.1  156.75]\n",
      "Index 431 - Y_all: [155.5  168.05 217.   151.1  163.35]\n",
      "Index 494 - Y_all: [153.55 169.   169.85 169.   169.  ]\n",
      "Index 512 - Y_all: [149.95 150.   169.   163.65 165.  ]\n",
      "Index 526 - Y_all: [140.6 141.3 162.  141.3 141.4]\n",
      "Index 555 - Y_all: [144.95 146.4  171.   145.   144.15]\n",
      "Index 573 - Y_all: [147.15 147.25 174.6  149.85 148.15]\n",
      "Index 586 - Y_all: [162.   168.15 179.45 204.7  164.35]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "X_all, Y_all ,labels= np.load(\"Train_Data/option_train__labeled_3m_06_06_2025.npz\", allow_pickle=True).values()\n",
    "# Find indices where label is \"STRONG BUY\"\n",
    "strong_buy_indices = np.where(labels == \"BUY\")[0]\n",
    "print(\"Indices with BUY:\", strong_buy_indices.shape)  \n",
    "# Print first such index and the corresponding Y_all\n",
    "print(\"Indices with STRONG BUY:\", strong_buy_indices[:10])  # first 10 indices\n",
    "print(\"\\nCorresponding Y_all values:\")\n",
    "for idx in strong_buy_indices[:10]:  # show first 5 examples\n",
    "    print(f\"Index {idx} - Y_all: {Y_all[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe101882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with BUY: (187617,)\n",
      "Indices with NO: (2195397,)\n"
     ]
    }
   ],
   "source": [
    "strong_buy_indices = np.where(labels == \"BUY\")[0]\n",
    "no_buy_indices= np.where(labels == \"NO\")[0]\n",
    "print(\"Indices with BUY:\", strong_buy_indices.shape)  \n",
    "print(\"Indices with NO:\", no_buy_indices.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
