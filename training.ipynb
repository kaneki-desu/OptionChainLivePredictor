{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca39c53f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:yellow\">Using RCABiLSTM</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ReverseCrossAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    RCA (Reverse Cross Attention) focuses attention more on recent time steps,\n",
    "    which is effective for financial time series.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, heads=5):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = heads\n",
    "        self.d_k = d_model // heads\n",
    "\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key   = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.out   = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, D)\n",
    "        B, T, D = x.shape\n",
    "\n",
    "        Q = self.query(x)  # (B, T, D)\n",
    "        K = self.key(torch.flip(x, dims=[1]))  # reverse time (RCA)\n",
    "        V = self.value(torch.flip(x, dims=[1]))\n",
    "\n",
    "        # Split into heads\n",
    "        Q = Q.view(B, T, self.heads, self.d_k).transpose(1, 2)  # (B, H, T, d_k)\n",
    "        K = K.view(B, T, self.heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(B, T, self.heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.d_k ** 0.5)  # (B, H, T, T)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn, V)  # (B, H, T, d_k)\n",
    "\n",
    "        # Concatenate heads\n",
    "        context = context.transpose(1, 2).contiguous().view(B, T, D)\n",
    "        return self.out(context)\n",
    "\n",
    "\n",
    "class RCABiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=15, hidden_dim=256, lstm_layers=5, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.rca = ReverseCrossAttention(d_model=input_dim, heads=5)\n",
    "        self.bilstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim,\n",
    "                              num_layers=lstm_layers, batch_first=True,\n",
    "                              bidirectional=True, dropout=dropout)\n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, 1024),  # 256 → 1024\n",
    "                nn.LayerNorm(1024),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(1024, 256),              # ✅ 1024 → 64 (NOT 256)\n",
    "                nn.GELU(),\n",
    "                nn.Linear(256, 64),              # ✅ 1024 → 64 (NOT 256)\n",
    "                nn.GELU(),\n",
    "                # nn.Linear(1024, 64),      \n",
    "                # nn.GELU(),         # 1024 → 64\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(64, 1)                  # 64 → 1 (final logit)\n",
    "            )           \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rca(x)\n",
    "        lstm_out, _ = self.bilstm(x)\n",
    "        x_last = lstm_out[:, -1, :]\n",
    "        logits = self.classifier(x_last)\n",
    "        return logits.squeeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"Train_Data/options_buy_model_data.pt\")\n",
    "X = data['X']           # shape: (N, 15, 15)\n",
    "# Y = data['Y']           # shape: (N, 5) — unused here\n",
    "labels = data['labels'] # shape: (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BuyDataset(Dataset):\n",
    "    def __init__(self, X_tensor, labels_tensor):\n",
    "        self.X = X_tensor.float()\n",
    "        self.y = labels_tensor.float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "# Replace NaNs with 0 or a safe default\n",
    "X = torch.nan_to_num(X, nan=0.0, posinf=10.0, neginf=-10.0)\n",
    "labels = torch.nan_to_num(labels, nan=0.0)\n",
    "\n",
    "dataset = BuyDataset(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size], generator=generator)\n",
    "train_loader = DataLoader(train_set, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# criterion = BinaryFocalLoss(alpha=0.5, gamma=1.0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RCABiLSTM(input_dim=15).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# Compute pos_weight = (# NO BUY) / (# BUY)\n",
    "pos_weight = torch.tensor([(451811 / 24792)* 0.2], dtype=torch.float).to(device)\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "epochs_without_improvement = 0\n",
    "num_epochs = 50  # or as you wish\n",
    "def train_model(model, train_loader, optimizer, criterion, device, log_every=200):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        y_batch = y_batch.float()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "        # 🧾 Log progress every `log_every` batches\n",
    "        if i % log_every == 0:\n",
    "            print(f\"🧩 Batch {i+1}/{len(train_loader)}: Loss={loss.item():.4f}\")\n",
    "\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).long()\n",
    "            correct += (preds == y_batch.long()).sum().item()\n",
    "\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "    return total_loss / len(val_loader.dataset), accuracy\n",
    "\n",
    "import os\n",
    "# Optional: Load previous best model if available\n",
    "if os.path.exists(\"best_model.pt\"):\n",
    "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "    print(\"📦 Loaded best model checkpoint.\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"📅 Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss - 1e-4:  # improvement\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        print(\"✅ Improvement! Model saved.\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"⏳ No improvement for {epochs_without_improvement} epoch(s).\")\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"⛔ Early stopping: validation loss hasn't improved in 3 epochs.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b212e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # criterion = BinaryFocalLoss(alpha=0.5, gamma=1.0)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = RCABiLSTM(input_dim=15).to(device)\n",
    "# model.eval()\n",
    "\n",
    "# import os\n",
    "# # Optional: Load previous best model if available\n",
    "# if os.path.exists(\"best_model.pt\"):\n",
    "#     model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "#     print(\"📦 Loaded best model checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "# If you're using a DataLoader (val_loader), collect all predictions\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).long()\n",
    "\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(y_batch.cpu().long())\n",
    "\n",
    "# Concatenate all batches\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['NO BUY', 'BUY'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"📉 Confusion Matrix: RCA-BiLSTM\")\n",
    "plt.show()\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_labels, all_preds, target_names=['NO BUY', 'BUY']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bcd5e2",
   "metadata": {},
   "source": [
    "optuna rcaBilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dda204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import optuna\n",
    "\n",
    "# === Load your preprocessed data ===\n",
    "data = torch.load(\"Train_Data/options_buy_model_data.pt\")\n",
    "X = torch.nan_to_num(data['X'])\n",
    "labels = torch.nan_to_num(data['labels'])\n",
    "\n",
    "# === Prepare dataset and dataloaders ===\n",
    "from torch.utils.data import Dataset, random_split, WeightedRandomSampler\n",
    "\n",
    "class BuyDataset(Dataset):\n",
    "    def __init__(self, X_tensor, labels_tensor):\n",
    "        self.X = X_tensor.float()\n",
    "        self.y = labels_tensor.float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "dataset = BuyDataset(X, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "# Extract indices for train_set\n",
    "train_indices = train_set.indices if hasattr(train_set, 'indices') else list(range(len(train_set)))\n",
    "\n",
    "# Subset labels for the training indices only\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "# Create weights for training labels only\n",
    "sample_weights = torch.where(train_labels == 1, 1.0, 0.05)\n",
    "\n",
    "# Use sampler on those indices\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(train_labels), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=1024, sampler=sampler)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=1024)\n",
    "\n",
    "# === Device ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pos_weight = torch.tensor([(len(labels) - labels.sum()) / labels.sum()], device=device)\n",
    "\n",
    "# === RCA Module ===\n",
    "class ReverseCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, heads=5):\n",
    "        super().__init__()\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, D = x.shape\n",
    "        Q = self.query(x)\n",
    "        K = self.key(torch.flip(x, dims=[1]))\n",
    "        V = self.value(torch.flip(x, dims=[1]))\n",
    "\n",
    "        Q = Q.view(B, T, self.heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(B, T, self.heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(B, T, self.heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.d_k ** 0.5)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn, V)\n",
    "        context = context.transpose(1, 2).contiguous().view(B, T, D)\n",
    "        return self.out(context)\n",
    "\n",
    "# === Asymmetric BCE Loss ===\n",
    "class AsymmetricBCELoss(nn.Module):\n",
    "    def __init__(self, fn_weight=1.0, fp_weight=5.0):\n",
    "        super().__init__()\n",
    "        self.fn_weight = fn_weight\n",
    "        self.fp_weight = fp_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        loss_pos = -self.fn_weight * targets * torch.log(probs + 1e-6)\n",
    "        loss_neg = -self.fp_weight * (1 - targets) * torch.log(1 - probs + 1e-6)\n",
    "        loss = loss_pos + loss_neg\n",
    "        return loss.mean()\n",
    "\n",
    "# === Training helpers ===\n",
    "def train_model(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            total_loss += loss.item() * len(X_batch)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "# === Objective function ===\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    mlp_dim = trial.suggest_categorical(\"mlp_dim\", [64, 128, 256])\n",
    "\n",
    "    class RCAModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.rca = ReverseCrossAttention(d_model=15, heads=5)\n",
    "            self.bilstm = nn.LSTM(input_size=15, hidden_size=hidden_dim,\n",
    "                                  num_layers=lstm_layers, batch_first=True,\n",
    "                                  bidirectional=True, dropout=dropout)\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, 1024),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(1024, mlp_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(mlp_dim, 1)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.rca(x)\n",
    "            out, _ = self.bilstm(x)\n",
    "            x_last = out[:, -1, :]\n",
    "            return self.classifier(x_last).squeeze(-1)\n",
    "\n",
    "    model = RCAModel().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = AsymmetricBCELoss(fn_weight=1.0, fp_weight=5.0)\n",
    "\n",
    "    for _ in range(3):\n",
    "        train_model(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate_model(model, val_loader, criterion)\n",
    "    return val_loss\n",
    "\n",
    "# === Run the study ===\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# === Print best result ===\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb6ef9e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:yellow\">Using lstm cell -inefficient </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b3f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# ----------------------------\n",
    "# Encoder using LSTMCell (manual 15-step)\n",
    "# ----------------------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        batch_size, seq_len, input_size = input_seq.shape\n",
    "        h = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        c = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = input_seq[:, t, :]  # shape: (batch, input_size)\n",
    "            h, c = self.lstm_cell(x_t, (h, c))\n",
    "\n",
    "        return h, c  # final hidden and cell state\n",
    "\n",
    "# ----------------------------\n",
    "# Decoder using LSTMCell (manual 5-step)\n",
    "# ----------------------------\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.input_projection = nn.Linear(output_size, input_size)  # 🔧 Fix\n",
    "\n",
    "    def forward(self, h, c, decoder_input, output_len):\n",
    "        outputs = []\n",
    "        for _ in range(output_len):\n",
    "            h, c = self.lstm_cell(decoder_input, (h, c))\n",
    "            out = self.output_layer(h)  # shape: (batch_size, output_size)\n",
    "            outputs.append(out)\n",
    "            decoder_input = self.input_projection(out)  # 🔧 Project back to input_size\n",
    "        return torch.stack(outputs, dim=1)  # shape: (batch_size, output_len, output_size)\n",
    "\n",
    "# ----------------------------\n",
    "# Seq2Seq wrapper\n",
    "# ----------------------------\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, output_len):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.output_len = output_len\n",
    "\n",
    "    def forward(self, src):\n",
    "        h, c = self.encoder(src)\n",
    "        decoder_input = src[:, -1, :]  # use last input as first decoder input\n",
    "        out_seq = self.decoder(h, c, decoder_input, self.output_len)\n",
    "        return out_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef838cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "# Hyperparams\n",
    "input_len = 15\n",
    "output_len = 5\n",
    "input_size = 10\n",
    "output_size = 1\n",
    "hidden_size = 256\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "# Generate and split data\n",
    "# X, Y = generate_data(n_samples=1200)\n",
    "X_all_scaled = joblib.load(\"scaler_X.pkl\")\n",
    "Y_all_scaled = joblib.load(\"scaler_Y.pkl\")\n",
    "# Ensure X_all_scaled and Y_all_scaled are numpy arrays\n",
    "X_all_scaled = np.array(X_all_scaled)\n",
    "Y_all_scaled = np.array(Y_all_scaled)\n",
    "\n",
    "X, Y = X_all_scaled, Y_all_scaled  # Use the preprocessed data\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, Y_train = X[:split_idx], Y[:split_idx]\n",
    "X_test, Y_test = X[split_idx:], Y[split_idx:]\n",
    "#Jumbling X_Train and Y_train\n",
    "perm = np.random.permutation(X_train.shape[0])\n",
    "X_train, Y_train = X_train[perm], Y_train[perm]\n",
    "# Convert to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).to(device)\n",
    "X_train = torch.nan_to_num(X_train)\n",
    "print(\"Any NaNs in X_train?\", torch.isnan(X_train).any().item())\n",
    "print(\"Any NaNs in Y_train?\", torch.isnan(Y_train).any().item())\n",
    "print(\"Any Infs in X_train?\", torch.isinf(X_train).any().item())\n",
    "print(\"Any Infs in Y_train?\", torch.isinf(Y_train).any().item())\n",
    "\n",
    "# ========================\n",
    "# Initialize Model\n",
    "# ========================\n",
    "encoder = Encoder(input_size, hidden_size).to(device)\n",
    "decoder = Decoder(input_size, hidden_size, output_size).to(device)\n",
    "model = Seq2Seq(encoder, decoder, output_len).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "# Training\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        x_batch = X_train[i:i + batch_size]\n",
    "        y_batch = Y_train[i:i + batch_size]\n",
    "\n",
    "        pred = model(x_batch)\n",
    "\n",
    "        y_batch = y_batch.unsqueeze(-1)  # ➕ Add this to match pred's shape\n",
    "        loss = criterion(pred, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # 👈 Add this line\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        print(f\"Batch {i // batch_size + 1}, Loss: {loss.item():.6f}\", end='\\r')\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / num_batches:.6f}\")\n",
    "print(\"\\nTraining complete.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63691c3e",
   "metadata": {},
   "source": [
    "<h3 style=\"Color:Yellow\">Custom Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib  # or just `import joblib` depending on version\n",
    "import numpy as np\n",
    "\n",
    "# Load scaler\n",
    "scaler_Y = joblib.load(\"Train_Data/scaler_Y.pkl\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X_batch, Y_batch) in enumerate(test_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        preds = model(X_batch)\n",
    "\n",
    "        # Reshape for unscaling\n",
    "        preds_np = preds.cpu().numpy().squeeze(-1)\n",
    "        targets_np = Y_batch.cpu().numpy()  # already (batch_size, pred_len)\n",
    "\n",
    "        # Unscale\n",
    "        preds_unscaled = scaler_Y.inverse_transform(preds_np).reshape(Y_batch.shape[0], -1)\n",
    "        targets_unscaled = scaler_Y.inverse_transform(targets_np).reshape(Y_batch.shape[0], -1)\n",
    "\n",
    "        # Print a few samples from this batch\n",
    "        print(f\"\\n🟦 Batch {i+1}\")\n",
    "        for j in range(min(3, len(preds_unscaled))):  # Only show top 3 per batch for readability\n",
    "            print(f\"Sample {j+1} — True: {targets_unscaled[j]}, Predicted: {preds_unscaled[j]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5515997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "# ========================\n",
    "# Testing and Plotting\n",
    "# ========================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test[:5])  # shape: (5, 5, 1)\n",
    "\n",
    "for i in range(5):\n",
    "    past = X_test[i].cpu().numpy().flatten()\n",
    "    true_future = Y_test[i].cpu().numpy().flatten()\n",
    "    predicted_future = preds[i].cpu().numpy().flatten()\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=past, mode='lines+markers', name='Past Input', line=dict(color='blue')))\n",
    "    fig.add_trace(go.Scatter(y=true_future, mode='lines+markers', name='True Future', line=dict(color='green')))\n",
    "    fig.add_trace(go.Scatter(y=predicted_future, mode='lines+markers', name='Predicted Future', line=dict(color='red', dash='dash')))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Option Price Forecast Sample {i+1}\",\n",
    "        xaxis_title=\"Time Step (0–14: past, 15–19: future)\",\n",
    "        yaxis_title=\"Price (Normalized)\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Define the model again for completeness\n",
    "class CustomEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len):\n",
    "        super(CustomEncoder, self).__init__()\n",
    "        self.lstm_cells = nn.ModuleList([nn.LSTMCell(input_dim, hidden_dim) for _ in range(seq_len)])\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h = torch.zeros(input_seq.size(0), hidden_dim).to(input_seq.device)\n",
    "        c = torch.zeros(input_seq.size(0), hidden_dim).to(input_seq.device)\n",
    "        for t in range(len(self.lstm_cells)):\n",
    "            h, c = self.lstm_cells[t](input_seq[:, t, :], (h, c))\n",
    "        return h, c\n",
    "\n",
    "class CustomDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, pred_len):\n",
    "        super(CustomDecoder, self).__init__()\n",
    "        self.lstm_cells = nn.ModuleList([nn.LSTMCell(output_dim, hidden_dim) for _ in range(pred_len)])\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, h, c, target_seq=None, teacher_forcing_ratio=0.0):\n",
    "        outputs = []\n",
    "        inp = torch.zeros(h.size(0), 1).to(h.device)  # initial input\n",
    "        for t, cell in enumerate(self.lstm_cells):\n",
    "            h, c = cell(inp, (h, c))\n",
    "            out = self.output_layer(h)\n",
    "            outputs.append(out.unsqueeze(1))\n",
    "            if target_seq is not None and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                inp = target_seq[:, t].unsqueeze(1)\n",
    "            else:\n",
    "                inp = out\n",
    "        return torch.cat(outputs, dim=1)\n",
    "class MemoryNetwork(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(MemoryNetwork, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        return self.net(h)\n",
    "class Seq2SeqLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, seq_len, pred_len):\n",
    "        super(Seq2SeqLSTM, self).__init__()\n",
    "        self.encoder = CustomEncoder(input_dim, hidden_dim, seq_len)\n",
    "        self.memory = MemoryNetwork(hidden_dim)\n",
    "        self.decoder = CustomDecoder(hidden_dim, output_dim, pred_len)\n",
    "\n",
    "    def forward(self, x, y=None, teacher_forcing_ratio=0.0):\n",
    "        h, c = self.encoder(x)\n",
    "        h = self.memory(h)\n",
    "        return self.decoder(h, c, y, teacher_forcing_ratio)\n",
    "\n",
    "# Initialize model\n",
    "input_dim = 10\n",
    "hidden_dim = 512\n",
    "output_dim = 1\n",
    "seq_len = 15\n",
    "pred_len = 5\n",
    "batch_size = 32\n",
    "model = Seq2SeqLSTM(input_dim, hidden_dim, output_dim, seq_len, pred_len)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss, optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model_summary = str(model)\n",
    "# print(model_summary[:700])  # return partial summary\n",
    "\n",
    "#loading the data\n",
    "import numpy as np\n",
    "data= np.load(\"Train_Data/option_train_data_scaled.npz\")\n",
    "print(data)\n",
    "X, Y = data['X_all'], data['Y_all']  # Use the preprocessed data\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, Y_train = X[:split_idx], Y[:split_idx]\n",
    "X_test, Y_test = X[split_idx:], Y[split_idx:]\n",
    "#Jumbling X_Train and Y_train\n",
    "perm = np.random.permutation(X_train.shape[0])\n",
    "X_train, Y_train = X_train[perm], Y_train[perm]\n",
    "# Convert to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).to(device)\n",
    "X_train = torch.nan_to_num(X_train)\n",
    "print(\"Any NaNs in X_train?\", torch.isnan(X_train).any().item())\n",
    "print(\"Any NaNs in Y_train?\", torch.isnan(Y_train).any().item())\n",
    "print(\"Any Infs in X_train?\", torch.isinf(X_train).any().item())\n",
    "print(\"Any Infs in Y_train?\", torch.isinf(Y_train).any().item())\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# 1. Create TensorDataset\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "\n",
    "# 2. Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "def train(model, dataloader, optimizer, loss_fn, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, (X_batch, Y_batch) in enumerate(dataloader):\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch, Y_batch, teacher_forcing_ratio=1.0)\n",
    "            loss = loss_fn(output, Y_batch.unsqueeze(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            print(f\"Batch {i // batch_size + 1}, Loss: {loss.item():.6f}\", end='\\r')\n",
    "        num_batches = len(X_train) // batch_size\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / num_batches:.6f}\")\n",
    "    print(\"\\nTraining complete.\\n\")\n",
    "train(model, train_loader, optimizer, criterion, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib  # or just `import joblib` depending on version\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Load scaler\n",
    "scaler_Y = joblib.load(\"Train_Data/scaler_Y.pkl\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X_batch, Y_batch) in enumerate(test_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        preds = model(X_batch)\n",
    "\n",
    "        # Reshape for unscaling\n",
    "        preds_np = preds.cpu().numpy().squeeze(-1)\n",
    "        targets_np = Y_batch.cpu().numpy()  # already (batch_size, pred_len)\n",
    "\n",
    "        # Unscale\n",
    "        preds_unscaled = scaler_Y.inverse_transform(preds_np).reshape(Y_batch.shape[0], -1)\n",
    "        targets_unscaled = scaler_Y.inverse_transform(targets_np).reshape(Y_batch.shape[0], -1)\n",
    "\n",
    "        # Print a few samples from this batch\n",
    "        print(f\"\\n🟦 Batch {i+1}\")\n",
    "        for j in range(min(3, len(preds_unscaled))):  # Only show top 3 per batch for readability\n",
    "            print(f\"Sample {j+1} — True: {targets_unscaled[j]}, Predicted: {preds_unscaled[j]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa5b5f7",
   "metadata": {},
   "source": [
    "<h3 style=\"Color:Yellow\">Custom Model- Single LSTM for Encoder and Decoder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Parameters\n",
    "total_points = 1000\n",
    "seq_len = 15\n",
    "pred_len = 5\n",
    "\n",
    "# Generate sine wave\n",
    "x = np.linspace(0, 100, total_points)\n",
    "wave = np.sin(x)  # or use np.cos(x)\n",
    "\n",
    "# Normalize the wave (optional, but often helpful)\n",
    "wave = (wave - wave.min()) / (wave.max() - wave.min())\n",
    "\n",
    "# Prepare sequences\n",
    "X, Y = [], []\n",
    "for i in range(len(wave) - seq_len - pred_len):\n",
    "    X.append(wave[i:i+seq_len])\n",
    "    Y.append(wave[i+seq_len:i+seq_len+pred_len])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Reshape for model input [batch, seq_len, input_dim]\n",
    "X = X[..., np.newaxis]  # shape: [N, seq_len, 1]\n",
    "Y = Y  # shape: [N, pred_len]\n",
    "\n",
    "print(X.shape, Y.shape)  # e.g. (980, 15, 1), (980, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a96b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import joblib\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ============================\n",
    "# Encoder\n",
    "# ============================\n",
    "class FastEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FastEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True ,num_layers=8, dropout=0.2,bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        output, (h, c) = self.lstm(input_seq)\n",
    "        return h, c  # return last layer's hidden and cell states\n",
    "\n",
    "# ============================\n",
    "# Decoder\n",
    "# ============================\n",
    "class FastDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, pred_len):\n",
    "        super(FastDecoder, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.lstm = nn.LSTM(output_dim, hidden_dim, batch_first=True ,num_layers=16, dropout=0.2)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, h, c, target_seq=None, teacher_forcing_ratio=0.0):\n",
    "        batch_size = h.size(1)\n",
    "        outputs = []\n",
    "        input_step = torch.zeros(batch_size, 1, 1).to(h.device)  # [batch, 1, output_dim]\n",
    "        hidden = (h, c)  # pass full hidden state\n",
    "\n",
    "        for t in range(self.pred_len):\n",
    "            out, hidden = self.lstm(input_step, hidden)\n",
    "            prediction = self.output_layer(out[:, -1, :])  # [batch, output_dim]\n",
    "            outputs.append(prediction.unsqueeze(1))  # [batch, 1, output_dim]\n",
    "\n",
    "            if target_seq is not None and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                input_step = target_seq[:, t].unsqueeze(1).unsqueeze(-1)  # ✅ FIXED\n",
    "            else:\n",
    "                input_step = prediction.unsqueeze(1)\n",
    "\n",
    "        return torch.cat(outputs, dim=1)  # [batch, pred_len, output_dim]\n",
    "\n",
    "# ============================\n",
    "# Memory Network\n",
    "# ============================\n",
    "class MemoryNetwork(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(MemoryNetwork, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, 1024),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(2048, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),  # Optional: stabilizes across features\n",
    "            nn.Tanh()  # For stable, bounded memory to decoder\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        return self.net(h)\n",
    "\n",
    "# ============================\n",
    "# Seq2Seq Model\n",
    "# ============================\n",
    "class FastSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, seq_len, pred_len):\n",
    "        super(FastSeq2Seq, self).__init__()\n",
    "        self.encoder = FastEncoder(input_dim, hidden_dim)\n",
    "        self.memory = MemoryNetwork(hidden_dim)\n",
    "        self.decoder = FastDecoder(hidden_dim, output_dim, pred_len)\n",
    "\n",
    "    def forward(self, x, y=None, teacher_forcing_ratio=0.0):\n",
    "        h, c = self.encoder(x)  # h, c: [num_layers=5, batch, hidden_dim]\n",
    "\n",
    "        # Enhance ALL layers of h using MemoryNetwork\n",
    "        num_layers, batch_size, hidden_dim = h.shape\n",
    "        h_reshaped = h.view(-1, hidden_dim)                     # [5 * B, H]\n",
    "        h_enhanced = self.memory(h_reshaped)                    # [5 * B, H]\n",
    "        h = h_enhanced.view(num_layers, batch_size, hidden_dim) # [5, B, H]\n",
    "\n",
    "        return self.decoder(h, c, y, teacher_forcing_ratio)\n",
    "\n",
    "# ============================\n",
    "# Model and Training Setup\n",
    "# ============================\n",
    "input_dim = 10\n",
    "hidden_dim = 512\n",
    "output_dim = 1\n",
    "seq_len = 15\n",
    "pred_len = 5\n",
    "\n",
    "model = FastSeq2Seq(input_dim, hidden_dim, output_dim, seq_len, pred_len)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ============================\n",
    "# Load and Prepare Data\n",
    "# ============================\n",
    "X_all_scaled, Y_all_scaled = np.load(\"Train_Data/option_train_data_scaled.npz\", allow_pickle=True).values()\n",
    "X, Y = X_all_scaled, Y_all_scaled\n",
    "\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, Y_train = X[:split_idx], Y[:split_idx]\n",
    "X_test, Y_test = X[split_idx:], Y[split_idx:]\n",
    "\n",
    "perm = np.random.permutation(X_train.shape[0])\n",
    "X_train, Y_train = X_train[perm], Y_train[perm]\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "X_train = torch.nan_to_num(X_train)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "scaler = torch.amp.GradScaler()\n",
    "print(\"hrwvbr\")\n",
    "# ============================\n",
    "# Training Function\n",
    "# ============================\n",
    "\n",
    "def weighted_mse_loss(pred, target, weights):\n",
    "    \"\"\"\n",
    "    pred, target: [batch, pred_len, output_dim]\n",
    "    weights: [pred_len] or [1, pred_len, 1]\n",
    "    \"\"\"\n",
    "    return ((weights * (pred - target) ** 2).mean())\n",
    "def weighted_mae_loss(pred, target, weights):\n",
    "    return (weights * torch.abs(pred - target)).mean()\n",
    "\n",
    "def train(model, dataloader, optimizer, weights, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        teacher_forcing_ratio = max(0, 1.0 - epoch / epochs)\n",
    "        total_loss = 0\n",
    "        count = 0  # to count how many batches are being included in total_loss\n",
    "        for i, (X_batch, Y_batch) in enumerate(dataloader):\n",
    "            X_batch = X_batch.to(device, non_blocking=True)\n",
    "            Y_batch = Y_batch.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                output = model(X_batch, Y_batch, teacher_forcing_ratio)  # [B, T, 1]\n",
    "                # loss = 0.8 * weighted_mae_loss(output, Y_batch.unsqueeze(-1), weights)+ 0.2 * weighted_mse_loss(output, Y_batch.unsqueeze(-1), weights)\n",
    "                loss= nn.MSELoss()(output, Y_batch.unsqueeze(-1))\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            # ✅ Gradient clipping step (place it BEFORE optimizer.step)\n",
    "            scaler.unscale_(optimizer)  # Unscale gradients for clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if i >= 50:  # Only count loss after 50th batch\n",
    "                total_loss += loss.item()\n",
    "                count += 1\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Batch {i + 1}, Loss: {loss.item():.6f}\", end='\\r')\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(dataloader):.6f}\")\n",
    "    print(\"\\n✅ Training complete.\\n\")\n",
    "\n",
    "# ============================\n",
    "# Start Training\n",
    "# ============================\n",
    "weights = torch.tensor([0.1, 0.1, 0.3, 0.7, 1.0], device=device).view(1, -1, 1)\n",
    "train(model, train_loader, optimizer,  weights, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0818621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib  # or just `import joblib` depending on version\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test_dataset = TensorDataset(X_train, Y_train)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Load scaler\n",
    "scaler_Y = joblib.load(\"Train_Data/scaler_Y.pkl\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X_batch, Y_batch) in enumerate(test_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        preds = model(X_batch)\n",
    "\n",
    "        # Reshape for unscaling\n",
    "        preds_np = preds.cpu().numpy().squeeze(-1)\n",
    "        targets_np = Y_batch.cpu().numpy()  # already (batch_size, pred_len)\n",
    "\n",
    "        # Unscale\n",
    "        preds_unscaled = scaler_Y.inverse_transform(preds_np).reshape(Y_batch.shape[0], -1)\n",
    "        targets_unscaled = scaler_Y.inverse_transform(targets_np).reshape(Y_batch.shape[0], -1)\n",
    "\n",
    "        # Print a few samples from this batch\n",
    "        print(f\"\\n🟦 Batch {i+1}\")\n",
    "        for j in range(min(3, len(preds_unscaled))):  # Only show top 3 per batch for readability\n",
    "            print(f\"Sample {j+1} — True: {targets_unscaled[j]}, Predicted: {preds_unscaled[j]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b52290",
   "metadata": {},
   "source": [
    "<h3 style=\"color:yellow\">Custom model with single attention layer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b94f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: [batch, hidden_dim]\n",
    "        # encoder_outputs: [batch, seq_len, hidden_dim]\n",
    "        batch_size, seq_len, _ = encoder_outputs.size()\n",
    "\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)  # [batch, seq_len, hidden_dim]\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [batch, seq_len, hidden_dim]\n",
    "        energy = energy @ self.v  # [batch, seq_len]\n",
    "        attn_weights = torch.softmax(energy, dim=1)  # [batch, seq_len]\n",
    "\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)  # [batch, 1, hidden_dim]\n",
    "        return context.squeeze(1), attn_weights  # [batch, hidden_dim], [batch, seq_len]\n",
    "class MemoryNetwork(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(MemoryNetwork, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        return h + self.net(h)\n",
    "\n",
    "\n",
    "class FastEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FastEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, num_layers=5, dropout=0.2)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        output, (h, c) = self.lstm(input_seq)\n",
    "        return output, (h, c)  # output: [batch, seq_len, hidden_dim]\n",
    "\n",
    "class FastDecoderWithAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, pred_len):\n",
    "        super(FastDecoderWithAttention, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.lstm_cell = nn.LSTMCell(hidden_dim + output_dim + 1, hidden_dim)  # +1 for time encoding\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, encoder_outputs, h, c, target_seq=None, teacher_forcing_ratio=0.0):\n",
    "        batch_size = h.size(1)\n",
    "        h, c = h[-1], c[-1]  # use last layer of stacked LSTM\n",
    "\n",
    "        outputs = []\n",
    "        input_step = torch.zeros(batch_size, 1).to(h.device)  # First decoder input is zeros\n",
    "\n",
    "        for t in range(self.pred_len):\n",
    "            context, _ = self.attention(h, encoder_outputs)  # context: [batch, hidden_dim]\n",
    "\n",
    "            # Create time encoding scalar: (t+1)/pred_len\n",
    "            time_encoding = torch.full((batch_size, 1), (t + 1) / self.pred_len, device=h.device)  # [batch, 1]\n",
    "\n",
    "            # Concatenate [prev_output, time_encoding, context]\n",
    "            rnn_input = torch.cat([input_step, time_encoding, context], dim=1)  # [batch, hidden_dim + 2]\n",
    "\n",
    "            h, c = self.lstm_cell(rnn_input, (h, c))\n",
    "            prediction = self.output_layer(h)  # [batch, output_dim]\n",
    "            outputs.append(prediction.unsqueeze(1))  # [batch, 1, output_dim]\n",
    "\n",
    "            if target_seq is not None and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                input_step = target_seq[:, t].unsqueeze(1)  # [batch, 1]\n",
    "            else:\n",
    "                input_step = prediction\n",
    "\n",
    "        return torch.cat(outputs, dim=1)  # [batch, pred_len, output_dim]\n",
    "\n",
    "class FastSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, seq_len, pred_len):\n",
    "        super(FastSeq2Seq, self).__init__()\n",
    "        self.encoder = FastEncoder(input_dim, hidden_dim)\n",
    "        self.memory = MemoryNetwork(hidden_dim)\n",
    "        self.decoder = FastDecoderWithAttention(hidden_dim, output_dim, pred_len)\n",
    "\n",
    "    def forward(self, x, y=None, teacher_forcing_ratio=0.0):\n",
    "        encoder_outputs, (h, c) = self.encoder(x)  # encoder_outputs: [batch, seq_len, hidden_dim]\n",
    "        \n",
    "        # Enhance encoder_outputs through memory\n",
    "        encoder_outputs = self.memory(encoder_outputs)  # still [batch, seq_len, hidden_dim]\n",
    "        \n",
    "        return self.decoder(encoder_outputs, h, c, y, teacher_forcing_ratio)\n",
    "\n",
    "# ============================\n",
    "# Model and Training Setup\n",
    "# ============================\n",
    "input_dim = 10\n",
    "hidden_dim = 512\n",
    "output_dim = 1\n",
    "seq_len = 15\n",
    "pred_len = 5\n",
    "\n",
    "model = FastSeq2Seq(input_dim, hidden_dim, output_dim, seq_len, pred_len)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ============================\n",
    "# Load and Prepare Data\n",
    "# ============================\n",
    "X_all_scaled, Y_all_scaled = np.load(\"Train_Data/option_train_data_scaled.npz\", allow_pickle=True).values()\n",
    "X, Y = X_all_scaled, Y_all_scaled\n",
    "\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, Y_train = X[:split_idx], Y[:split_idx]\n",
    "X_test, Y_test = X[split_idx:], Y[split_idx:]\n",
    "\n",
    "perm = np.random.permutation(X_train.shape[0])\n",
    "X_train, Y_train = X_train[perm], Y_train[perm]\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "X_train = torch.nan_to_num(X_train)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "scaler = torch.amp.GradScaler()\n",
    "print(\"hrwvbr\")\n",
    "# ============================\n",
    "# Training Function\n",
    "# ============================\n",
    "\n",
    "def weighted_mse_loss(pred, target, weights):\n",
    "    \"\"\"\n",
    "    pred, target: [batch, pred_len, output_dim]\n",
    "    weights: [pred_len] or [1, pred_len, 1]\n",
    "    \"\"\"\n",
    "    return ((weights * (pred - target) ** 2).mean())\n",
    "def weighted_mae_loss(pred, target, weights):\n",
    "    return (weights * torch.abs(pred - target)).mean()\n",
    "\n",
    "def variance_loss(pred):\n",
    "    # pred: [batch, pred_len, output_dim]\n",
    "    var = torch.var(pred, dim=1)  # Variance across timesteps\n",
    "    return -var.mean()  # Encourage variance\n",
    "\n",
    "def trend_loss(pred, target):\n",
    "    # Difference between consecutive steps\n",
    "    pred_diff = pred[:, 1:, :] - pred[:, :-1, :]\n",
    "    target_diff = target[:, 1:, :] - target[:, :-1, :]\n",
    "    return nn.L1Loss()(pred_diff, target_diff)\n",
    "\n",
    "def composite_loss(pred, target, weights):\n",
    "    pred = pred.float()\n",
    "    target = target.float()\n",
    "    \n",
    "    mae = weighted_mae_loss(pred, target, weights)\n",
    "    mse = weighted_mse_loss(pred, target, weights)\n",
    "    var_penalty = variance_loss(pred)  # Encourage diversity across steps\n",
    "    tr_loss = trend_loss(pred, target)\n",
    "\n",
    "    # You can tune these weights\n",
    "    total = (\n",
    "        0.4 * mae +\n",
    "        0.3 * mse +\n",
    "        0.2 * tr_loss +\n",
    "        0.1 * var_penalty\n",
    "    )\n",
    "    return total\n",
    "\n",
    "def train(model, dataloader, optimizer, weights, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        teacher_forcing_ratio = max(0, 1.0 - epoch / epochs)\n",
    "        total_loss = 0\n",
    "        for i, (X_batch, Y_batch) in enumerate(dataloader):\n",
    "            X_batch = X_batch.to(device, non_blocking=True)\n",
    "            Y_batch = Y_batch.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type='cuda'):\n",
    "                output = model(X_batch, Y_batch, teacher_forcing_ratio)  # [B, T, 1]\n",
    "                loss = composite_loss(output, Y_batch.unsqueeze(-1), weights)\n",
    "                \n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"⚠️ Skipping batch {i+1} due to invalid loss: {loss.item()}\")\n",
    "                continue  # Don't backward/update on invalid gradients\n",
    "            scaler.scale(loss).backward()\n",
    "            # ✅ Gradient clipping step (place it BEFORE optimizer.step)\n",
    "            scaler.unscale_(optimizer)  # Unscale gradients for clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Batch {i + 1}, Loss: {loss.item():.6f}\", end='\\r')\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(dataloader):.6f}\")\n",
    "    print(\"\\n✅ Training complete.\\n\")\n",
    "\n",
    "# ============================\n",
    "# Start Training\n",
    "# ============================\n",
    "weights = torch.tensor([0.1, 0.1, 0.3, 0.7, 1.0], device=device).view(1, -1, 1)\n",
    "train(model, train_loader, optimizer,  weights, epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib  # or just `import joblib` depending on version\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test_dataset = TensorDataset(X_train, Y_train)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Load scaler\n",
    "scaler_Y = joblib.load(\"Train_Data/scaler_Y.pkl\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X_batch, Y_batch) in enumerate(test_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        preds = model(X_batch)\n",
    "\n",
    "        # Reshape for unscaling\n",
    "        preds_np = preds.cpu().numpy().squeeze(-1)\n",
    "        targets_np = Y_batch.cpu().numpy()  # already (batch_size, pred_len)\n",
    "\n",
    "        # Unscale\n",
    "        preds_unscaled = scaler_Y.inverse_transform(preds_np).reshape(Y_batch.shape[0], -1)\n",
    "        targets_unscaled = scaler_Y.inverse_transform(targets_np).reshape(Y_batch.shape[0], -1)\n",
    "\n",
    "        # Print a few samples from this batch\n",
    "        print(f\"\\n🟦 Batch {i+1}\")\n",
    "        for j in range(min(3, len(preds_unscaled))):  # Only show top 3 per batch for readability\n",
    "            print(f\"Sample {j+1} — True: {targets_unscaled[j]}, Predicted: {preds_unscaled[j]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762f6a0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:yellow\">Attention all you need transformer </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f84c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# --- Positional Encoding ---\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)  # [max_len, d_model]\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)  # [max_len, 1]\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len, d_model]\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "\n",
    "\n",
    "# --- Transformer Encoder Layer ---\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dim_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_ff, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # Self-attention + residual\n",
    "        attn_output, _ = self.self_attn(src, src, src)\n",
    "        src = self.norm1(src + self.dropout(attn_output))\n",
    "\n",
    "        # Feedforward + residual\n",
    "        ff_output = self.ff(src)\n",
    "        src = self.norm2(src + self.dropout(ff_output))\n",
    "        return src\n",
    "\n",
    "\n",
    "# --- Transformer Decoder Layer ---\n",
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dim_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, heads, dropout=dropout, batch_first=True)\n",
    "        self.cross_attn = nn.MultiheadAttention(d_model, heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_ff, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt, memory):\n",
    "        # Self-attention\n",
    "        attn1, _ = self.self_attn(tgt, tgt, tgt)\n",
    "        tgt = self.norm1(tgt + self.dropout(attn1))\n",
    "\n",
    "        # Cross-attention\n",
    "        attn2, _ = self.cross_attn(tgt, memory, memory)\n",
    "        tgt = self.norm2(tgt + self.dropout(attn2))\n",
    "\n",
    "        # Feedforward\n",
    "        ff = self.ff(tgt)\n",
    "        tgt = self.norm3(tgt + self.dropout(ff))\n",
    "        return tgt\n",
    "\n",
    "\n",
    "# --- Full Transformer Seq2Seq ---\n",
    "class TransformerSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim_enc, input_dim_dec, d_model=128, num_layers=6, heads=8, dim_ff=512, dropout=0.1, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.encoder_input_proj = nn.Linear(input_dim_enc, d_model)  # For 10 input features\n",
    "        self.decoder_input_proj = nn.Linear(input_dim_dec, d_model)  # For 1 decoder feature (past price)\n",
    "\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            TransformerEncoderLayer(d_model, heads, dim_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.decoder = nn.ModuleList([\n",
    "            TransformerDecoderLayer(d_model, heads, dim_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        src: [batch, src_len, input_dim_enc=10]\n",
    "        tgt: [batch, tgt_len, input_dim_dec=1]\n",
    "        \"\"\"\n",
    "        # Project and position encode\n",
    "        src = self.pos_enc(self.encoder_input_proj(src))  # [B, src_len, d_model]\n",
    "        tgt = self.pos_enc(self.decoder_input_proj(tgt))  # [B, tgt_len, d_model]\n",
    "\n",
    "        # Pass through encoder\n",
    "        for layer in self.encoder:\n",
    "            src = layer(src)\n",
    "\n",
    "        # Pass through decoder\n",
    "        for layer in self.decoder:\n",
    "            tgt = layer(tgt, src)\n",
    "\n",
    "        return self.output_layer(tgt)  # [B, tgt_len, output_dim]\n",
    "\n",
    "# Model Parameters\n",
    "input_dim_enc = 10    # Input features for encoder (option data)\n",
    "input_dim_dec = 1     # Input features for decoder (past predicted price or 0)\n",
    "output_dim = 1        # Final predicted option price\n",
    "d_model = 128         # Transformer hidden dimension\n",
    "num_layers = 6        # Number of encoder/decoder layers\n",
    "heads = 8             # Multi-head attention heads\n",
    "dim_ff = 512          # Feedforward network dimension\n",
    "dropout = 0.1         # Dropout probability\n",
    "\n",
    "# Initialize model\n",
    "model = TransformerSeq2Seq(\n",
    "    input_dim_enc=input_dim_enc,\n",
    "    input_dim_dec=input_dim_dec,\n",
    "    d_model=d_model,\n",
    "    num_layers=num_layers,\n",
    "    heads=heads,\n",
    "    dim_ff=dim_ff,\n",
    "    dropout=dropout,\n",
    "    output_dim=output_dim\n",
    ")\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# === Load Data ===\n",
    "X_all_scaled, Y_all_scaled = np.load(\"Train_Data/option_train_data_scaled.npz\", allow_pickle=True).values()\n",
    "X, Y = X_all_scaled, Y_all_scaled\n",
    "\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, Y_train = X[:split_idx], Y[:split_idx]\n",
    "X_test, Y_test = X[split_idx:], Y[split_idx:]\n",
    "\n",
    "perm = np.random.permutation(X_train.shape[0])\n",
    "X_train, Y_train = X_train[perm], Y_train[perm]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "X_train = torch.nan_to_num(X_train)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# === Loss Functions ===\n",
    "def weighted_mse_loss(pred, target, weights):\n",
    "    weights = weights.view(1, -1, 1)  # [1, pred_len, 1]\n",
    "    return ((weights * (pred - target) ** 2).mean())\n",
    "\n",
    "def weighted_mae_loss(pred, target, weights):\n",
    "    weights = weights.view(1, -1, 1)\n",
    "    return (weights * torch.abs(pred - target)).mean()\n",
    "\n",
    "def variance_loss(pred):\n",
    "    var = torch.var(pred, dim=1, unbiased=False)\n",
    "    return -var.mean()\n",
    "\n",
    "def trend_loss(pred, target):\n",
    "    pred_diff = pred[:, 1:, :] - pred[:, :-1, :]\n",
    "    target_diff = target[:, 1:, :] - target[:, :-1, :]\n",
    "    return nn.L1Loss()(pred_diff, target_diff)\n",
    "\n",
    "def composite_loss(pred, target, weights):\n",
    "    pred = pred.float()\n",
    "    target = target.float()\n",
    "    \n",
    "    mae = weighted_mae_loss(pred, target, weights)\n",
    "    mse = weighted_mse_loss(pred, target, weights)\n",
    "    var_penalty = variance_loss(pred)\n",
    "    tr_loss = trend_loss(pred, target)\n",
    "\n",
    "    return (\n",
    "        0.4 * mae +\n",
    "        0.3 * mse +\n",
    "        0.2 * tr_loss +\n",
    "        0.1 * var_penalty\n",
    "    )\n",
    "\n",
    "# === Training Function ===\n",
    "def train_transformer(model, dataloader, optimizer, loss_fn, device, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for X_batch, Y_batch in dataloader:\n",
    "            X_batch = X_batch.to(device).float()\n",
    "            Y_batch = Y_batch.to(device).float()\n",
    "\n",
    "            # Decoder input: shifted target\n",
    "            decoder_input = torch.zeros(Y_batch.size(0), Y_batch.size(1), 1).to(device)\n",
    "            decoder_input[:, 1:, 0] = Y_batch[:, :-1]\n",
    "\n",
    "            weights = torch.tensor([0.3, 0.3, 0.5, 0.7, 1.0], device=device)\n",
    "            output = model(X_batch, decoder_input)  # [B, 5, 1]\n",
    "            \n",
    "            # loss_fn expects both to be [B, 5, 1]\n",
    "            Y_batch = Y_batch.unsqueeze(-1)         # [B, 5, 1]\n",
    "            loss = loss_fn(output, Y_batch, weights)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            print(f\"Batch Loss: {loss.item():.6f}\", end='\\r')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(dataloader):.6f}\")\n",
    "\n",
    "# === Train ===\n",
    "train_transformer(model, train_loader, optimizer, loss_fn=composite_loss, device=device, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36260739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib  # or just `import joblib` depending on version\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test_dataset = TensorDataset(X_train, Y_train)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Load scaler\n",
    "scaler_Y = joblib.load(\"Train_Data/scaler_Y.pkl\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler  # if not already imported\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X_batch, Y_batch) in enumerate(test_loader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device)\n",
    "\n",
    "        batch_size = X_batch.size(0)\n",
    "        pred_len = Y_batch.size(1)  # e.g., 5\n",
    "        decoder_input = torch.zeros(batch_size, pred_len, 1).to(device)\n",
    "\n",
    "        # Autoregressive decoding\n",
    "        for t in range(pred_len):\n",
    "            # Run model on current decoder input\n",
    "            output = model(X_batch, decoder_input)\n",
    "\n",
    "            # Extract the prediction at current timestep\n",
    "            decoder_input[:, t, 0] = output[:, t, 0]\n",
    "\n",
    "        # Unscale predictions and targets\n",
    "        preds_np = decoder_input.cpu().numpy().squeeze(-1)  # [batch, pred_len]\n",
    "        targets_np = Y_batch.cpu().numpy()  # [batch, pred_len]\n",
    "\n",
    "        preds_unscaled = scaler_Y.inverse_transform(preds_np)\n",
    "        targets_unscaled = scaler_Y.inverse_transform(targets_np)\n",
    "\n",
    "        print(f\"\\n🟦 Batch {i+1}\")\n",
    "        for j in range(min(3, len(preds_unscaled))):  # Print top 3 per batch\n",
    "            print(f\"Sample {j+1} — True: {targets_unscaled[j]}, Predicted: {preds_unscaled[j]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preds_np.shape == targets_np.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767c4ed",
   "metadata": {},
   "source": [
    "<h3>Training for labelled</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d304cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================\n",
    "# Model Parameters\n",
    "# ============================\n",
    "input_dim = 10\n",
    "hidden_dim = 1024\n",
    "num_layers = 4\n",
    "dropout = 0.2\n",
    "output_dim = 2  # \"BUY\" or \"NO\"\n",
    "batch_size = 16\n",
    "n_heads = 4\n",
    "\n",
    "# ============================\n",
    "# FastEncoder with Self-Attention\n",
    "# ============================\n",
    "class FastEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout, n_heads):\n",
    "        super(FastEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True,\n",
    "                            num_layers=num_layers, dropout=dropout, bidirectional=True)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=hidden_dim * 2, num_heads=n_heads, batch_first=True)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)  # [B, T, 2H]\n",
    "        attn_out, _ = self.attn(lstm_out, lstm_out, lstm_out)  # [B, T, 2H]\n",
    "        pooled = self.pool(attn_out.transpose(1, 2)).squeeze(-1)  # [B, 2H]\n",
    "        return pooled\n",
    "\n",
    "# ============================\n",
    "# Memory Network\n",
    "# ============================\n",
    "class MemoryNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(MemoryNetwork, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(input_dim),\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, h):\n",
    "        return self.net(h)\n",
    "\n",
    "# ============================\n",
    "# Classifier Head\n",
    "# ============================\n",
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ClassifierHead, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# ============================\n",
    "# Full Classification Model\n",
    "# ============================\n",
    "class FastClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout, output_dim, n_heads):\n",
    "        super(FastClassifier, self).__init__()\n",
    "        self.encoder = FastEncoder(input_dim, hidden_dim, num_layers, dropout, n_heads)\n",
    "        self.memory = MemoryNetwork(hidden_dim * 2, hidden_dim * 2)\n",
    "        self.classifier = ClassifierHead(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = self.memory(h)\n",
    "        return self.classifier(h)\n",
    "\n",
    "# ============================\n",
    "# Load and Prepare Data\n",
    "# ============================\n",
    "X_all, Y_all, label = np.load(\"Train_Data/option_train_labeled_3m.npz\", allow_pickle=True).values()\n",
    "label_map = {'NO': 0, 'BUY': 1}\n",
    "Y_numeric = np.array([label_map[y] for y in label])\n",
    "\n",
    "split_idx = int(len(X_all) * 0.8)\n",
    "X_train, Y_train = X_all[:split_idx], Y_numeric[:split_idx]\n",
    "X_test, Y_test = X_all[split_idx:], Y_numeric[split_idx:]\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "X_train = torch.nan_to_num(X_train)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# ============================\n",
    "# Training Setup\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FastClassifier(input_dim, hidden_dim, num_layers, dropout, output_dim, n_heads).to(device)\n",
    "\n",
    "# Compute class weights for imbalanced classification\n",
    "class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=Y_numeric)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "# ============================\n",
    "# Training Function\n",
    "# ============================\n",
    "def train_model(model, loader, optimizer, criterion, test_loader, device, epochs=20):\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device_type='cuda' if device.type == 'cuda' else 'cpu'):\n",
    "                output = model(X_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"⚠️ Skipping batch due to invalid loss: {loss.item()}\")\n",
    "                continue\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        # Evaluate test set\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, Y_batch in test_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                Y_batch = Y_batch.to(device)\n",
    "\n",
    "                preds = model(X_batch)\n",
    "                loss = criterion(preds, Y_batch)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                predicted_classes = torch.argmax(preds, dim=1)\n",
    "                test_correct += (predicted_classes == Y_batch).sum().item()\n",
    "                test_total += Y_batch.size(0)\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        test_accuracy = 100.0 * test_correct / test_total\n",
    "\n",
    "        if avg_test_loss > best_loss:\n",
    "            print(\"⛔ Early stopping: Test loss increased.\")\n",
    "            break\n",
    "        else:\n",
    "            best_loss = avg_test_loss\n",
    "\n",
    "        train_acc = 100.0 * correct / total\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} | Train Loss: {total_loss / len(loader):.6f} | Train Acc: {train_acc:.2f}% | Test Acc: {test_accuracy:.2f}%\")\n",
    "\n",
    "# ============================\n",
    "# Confusion Matrix Plot\n",
    "# ============================\n",
    "def plot_confusion(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            preds = model(X_batch)\n",
    "            preds = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_true.extend(Y_batch.numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_true, all_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"NO\", \"BUY\"], yticklabels=[\"NO\", \"BUY\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# ============================\n",
    "# Train and Evaluate\n",
    "# ============================\n",
    "train_model(model, train_loader, optimizer, criterion, test_loader, device, epochs=20)\n",
    "plot_confusion(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, loss_fn, device, epochs=20, patience=3):\n",
    "    model.train()\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = torch.nan_to_num(X_batch).to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # === Validation loss ===\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val = torch.nan_to_num(X_val).to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                val_outputs = model(X_val)\n",
    "                val_loss += loss_fn(val_outputs, y_val).item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # === Early Stopping Check ===\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "        model.train()\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "train(model, train_loader,test_loader, optimizer,loss_fn= criterion, device='cuda', epochs=10)\n",
    "evaluate(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a0687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# === Evaluate on Test Set ===\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in DataLoader(TensorDataset(X_test, y_test), batch_size=512):\n",
    "        X_batch = torch.nan_to_num(X_batch).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        outputs = model(X_batch)  # [B, num_classes]\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_targets.append(y_batch.cpu().numpy())\n",
    "\n",
    "# === Flatten Arrays ===\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_targets = np.concatenate(all_targets)\n",
    "\n",
    "# === Confusion Matrix ===\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "labels = ['NO', 'BUY']  # Adjust if your label order is different\n",
    "\n",
    "# === Plot Confusion Matrix ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# === Optional: Print classification report ===\n",
    "print(classification_report(all_targets, all_preds, target_names=labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
